{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d5b8dfb3",
   "metadata": {},
   "source": [
    "# Personal Running Code"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d49e9a7",
   "metadata": {},
   "source": [
    "## Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a537c888",
   "metadata": {},
   "source": [
    "### Scanning documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bea1e10c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Quiet, progress-friendly PDF loader ---\n",
    "import time, logging, warnings, contextlib, io\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "\n",
    "# 1) Silence pypdf chatter/warnings\n",
    "try:\n",
    "    from pypdf.errors import PdfReadWarning\n",
    "    warnings.filterwarnings(\"ignore\", category=PdfReadWarning)\n",
    "except Exception:\n",
    "    pass  # older pypdf versions may not expose PdfReadWarning\n",
    "\n",
    "logging.getLogger(\"pypdf\").setLevel(logging.ERROR)\n",
    "\n",
    "# 2) Load PDFs with a progress bar (no ipywidgets required)\n",
    "from langchain.document_loaders import PyPDFLoader\n",
    "\n",
    "pdf_dir = Path(\"data\")\n",
    "pdf_paths = sorted(pdf_dir.rglob(\"*.pdf\"))\n",
    "\n",
    "docs = []\n",
    "start = time.perf_counter()\n",
    "\n",
    "print(f\"Scanning {len(pdf_paths)} PDFs in {pdf_dir.resolve()} ...\")\n",
    "for p in tqdm(pdf_paths, desc=\"Loading PDFs\", unit=\"file\"):\n",
    "    try:\n",
    "        # Some libraries print to stderr; swallow it to keep the notebook clean\n",
    "        with contextlib.redirect_stderr(io.StringIO()):\n",
    "            loader = PyPDFLoader(str(p))\n",
    "            docs.extend(loader.load())\n",
    "    except Exception as e:\n",
    "        print(f\":warning: Skipped {p.name}: {e}\")\n",
    "\n",
    "elapsed = time.perf_counter() - start\n",
    "print(f\"Done. Loaded {len(docs)} document chunks from {len(pdf_paths)} PDF files in {elapsed:,.1f}s.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15331941",
   "metadata": {},
   "source": [
    "### Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77f0954f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Split (unchanged) ---\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
    "split_docs = splitter.split_documents(docs)\n",
    "print(f\"Chunks after splitting: {len(split_docs)}\")\n",
    "\n",
    "# --- Embeddings (new import path) ---\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "embeddings = HuggingFaceEmbeddings(\n",
    "    model_name=\"sentence-transformers/all-MiniLM-L6-v2\",\n",
    "    encode_kwargs={\"normalize_embeddings\": True}  # IP == cosine\n",
    ")\n",
    "\n",
    "# --- In-memory vector store (Chroma) ---\n",
    "from langchain_community.vectorstores import Chroma  # works with LangChain 0.2+\n",
    "\n",
    "# build an in-memory index from your split_docs\n",
    "db = Chroma.from_documents(split_docs, embeddings)   # no persist_directory -> RAM only\n",
    "retriever = db.as_retriever(search_kwargs={\"k\": 5})\n",
    "\n",
    "print(\"Chroma (in-memory) vector store ready ✅\")\n",
    "\n",
    "\n",
    "# --- Retriever (choose one) ---\n",
    "retriever = db.as_retriever(search_kwargs={\"k\": 5})\n",
    "# retriever = db.as_retriever(search_type=\"mmr\",\n",
    "#                             search_kwargs={\"k\": 8, \"fetch_k\": 50, \"lambda_mult\": 0.5})\n",
    "\n",
    "# --- QA chain (HF example; swap if needed) ---\n",
    "from langchain_huggingface import HuggingFaceEndpoint\n",
    "from langchain.chains import RetrievalQA\n",
    "\n",
    "llm = HuggingFaceEndpoint(\n",
    "    repo_id=\"google/flan-t5-base\",\n",
    "    temperature=0,\n",
    "    max_new_tokens=512,\n",
    ")\n",
    "\n",
    "qa_chain = RetrievalQA.from_chain_type(\n",
    "    llm=llm, chain_type=\"stuff\", retriever=retriever, return_source_documents=True\n",
    ")\n",
    "print(\"Pipeline ready ✅\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afe9b7bd",
   "metadata": {},
   "source": [
    "### Smaller chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "440c9e6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "\n",
    "# Split into chunks of ~1000 characters with 200-character overlap\n",
    "text_splitter = CharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
    "split_docs = text_splitter.split_documents(documents)\n",
    "\n",
    "print(f\"Total chunks after splitting: {len(split_docs)}\")\n",
    "print(\"\\n--- Preview of first chunk ---\\n\")\n",
    "print(split_docs[0].page_content[:500])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2a5a826",
   "metadata": {},
   "source": [
    "### Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df0ad083",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "\n",
    "embeddings = HuggingFaceEmbeddings()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "745a8223",
   "metadata": {},
   "source": [
    "### Vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "453c78a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.vectorstores import FAISS\n",
    "\n",
    "db = FAISS.from_documents(split_docs, embeddings)\n",
    "retriever = db.as_retriever()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d8f625c",
   "metadata": {},
   "source": [
    "## Test Cases"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "705e03fe",
   "metadata": {},
   "source": [
    "### UC1: Find Particular Documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39568f37",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"Where is the CAPP final report from 2024?\"\n",
    "result = qa_chain({\"query\": query})\n",
    "\n",
    "print(\"\\n--- UC1: Find Particular Documents ---\\n\")\n",
    "print(\"Response:\", result[\"result\"], \"\\n\")\n",
    "\n",
    "print(\"Documents used:\")\n",
    "for doc in result[\"source_documents\"]:\n",
    "    print(f\"{doc.metadata.get('source', 'unknown')} \\n{doc.page_content[:200]}...\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb84198f",
   "metadata": {},
   "source": [
    "UC2: Summarize Particular Documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d0925a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"Summarize the CAPP final report from 2024\"\n",
    "result = qa_chain({\"query\": query})\n",
    "\n",
    "print(\"\\n--- UC2: Summarize Particular Documents ---\\n\")\n",
    "print(\"Summary:\", result[\"result\"], \"\\n\")\n",
    "\n",
    "print(\"Documents used:\")\n",
    "for doc in result[\"source_documents\"]:\n",
    "    print(f\"{doc.metadata.get('source', 'unknown')}\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a9dd0c2",
   "metadata": {},
   "source": [
    "UC3: Find Documents by Contents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a094f93d",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"Find documents related to system executive policies on AI\"\n",
    "result = qa_chain({\"query\": query})\n",
    "\n",
    "print(\"\\n--- UC3: Find Documents by Contents ---\\n\")\n",
    "print(\"Response:\", result[\"result\"], \"\\n\")\n",
    "\n",
    "print(\"Documents used:\")\n",
    "for doc in result[\"source_documents\"]:\n",
    "    print(f\"{doc.metadata.get('source', 'unknown')}\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df412962",
   "metadata": {},
   "source": [
    "UC4: Finding Particular Information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09bf2cce",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"When were votes on AI policies conducted?\"\n",
    "result = qa_chain({\"query\": query})\n",
    "\n",
    "print(\"\\n--- UC4: Finding Particular Information ---\\n\")\n",
    "print(\"Response:\", result[\"result\"], \"\\n\")\n",
    "\n",
    "print(\"Documents used:\")\n",
    "for doc in result[\"source_documents\"]:\n",
    "    print(f\"{doc.metadata.get('source', 'unknown')}\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c527360",
   "metadata": {},
   "source": [
    "UC5: Finding Related Information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fb6e0ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"Show me the history of resolutions on GE\"\n",
    "result = qa_chain({\"query\": query})\n",
    "\n",
    "print(\"\\n--- UC5: Finding Related Information ---\\n\")\n",
    "print(\"Response:\", result[\"result\"], \"\\n\")\n",
    "\n",
    "print(\"Documents used:\")\n",
    "for doc in result[\"source_documents\"]:\n",
    "    print(f\"{doc.metadata.get('source', 'unknown')}\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a986ea3",
   "metadata": {},
   "source": [
    "UC6: Refinement of Found Information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7035c1fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"In the history of resolutions you showed me, which ones are supportive or opposing GE reforms?\"\n",
    "result = qa_chain({\"query\": query})\n",
    "\n",
    "print(\"\\n--- UC6: Refinement of Found Information ---\\n\")\n",
    "print(\"Response:\", result[\"result\"], \"\\n\")\n",
    "\n",
    "print(\"Documents used:\")\n",
    "for doc in result[\"source_documents\"]:\n",
    "    print(f\"{doc.metadata.get('source', 'unknown')}\\n\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rag_workshop_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
