{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d5b8dfb3",
   "metadata": {},
   "source": [
    "# Personal Running Code"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d49e9a7",
   "metadata": {},
   "source": [
    "## Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a537c888",
   "metadata": {},
   "source": [
    "### Scanning documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bea1e10c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- PDF Load ---\n",
    "import time, logging, warnings, contextlib, io\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "\n",
    "# 1) Silence warnings (offsets)\n",
    "try:\n",
    "    from pypdf.errors import PdfReadWarning\n",
    "    warnings.filterwarnings(\"ignore\", category=PdfReadWarning)\n",
    "except Exception:\n",
    "    pass\n",
    "\n",
    "logging.getLogger(\"pypdf\").setLevel(logging.ERROR)\n",
    "\n",
    "# 2) Prog bar\n",
    "from langchain.document_loaders import PyPDFLoader\n",
    "\n",
    "pdf_dir = Path(\"data\")\n",
    "pdf_paths = sorted(pdf_dir.rglob(\"*.pdf\"))\n",
    "\n",
    "docs = []\n",
    "start = time.perf_counter()\n",
    "\n",
    "print(f\"Scanning {len(pdf_paths)} PDFs in {pdf_dir.resolve()} ...\")\n",
    "for p in tqdm(pdf_paths, desc=\"Loading PDFs\", unit=\"file\"):\n",
    "    try:\n",
    "        # Clean notebook\n",
    "        with contextlib.redirect_stderr(io.StringIO()):\n",
    "            loader = PyPDFLoader(str(p))\n",
    "            docs.extend(loader.load())\n",
    "    except Exception as e:\n",
    "        print(f\":warning: Skipped {p.name}: {e}\")\n",
    "\n",
    "elapsed = time.perf_counter() - start\n",
    "print(f\"Done. Loaded {len(docs)} document chunks from {len(pdf_paths)} PDF files in {elapsed:,.1f}s.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15331941",
   "metadata": {},
   "source": [
    "### Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77f0954f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Split ---\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
    "split_docs = splitter.split_documents(docs)\n",
    "print(f\"Split Chunks: {len(split_docs)}\")\n",
    "\n",
    "# --- Embeddings --\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "embeddings = HuggingFaceEmbeddings(\n",
    "    model_name=\"sentence-transformers/all-MiniLM-L6-v2\",\n",
    "    encode_kwargs={\"normalize_embeddings\": True}\n",
    ")\n",
    "\n",
    "# --- Chroma vector store ---\n",
    "from langchain_community.vectorstores import Chroma\n",
    "\n",
    "# in-memory index - split_docs\n",
    "db = Chroma.from_documents(split_docs, embeddings)   # RAM only\n",
    "retriever = db.as_retriever(search_kwargs={\"k\": 5})\n",
    "\n",
    "print(\"CChroma Vector Store: Ready\")\n",
    "\n",
    "\n",
    "# --- Retriever ---\n",
    "retriever = db.as_retriever(search_kwargs={\"k\": 5})\n",
    "\n",
    "# --- QA ---\n",
    "from langchain_huggingface import HuggingFaceEndpoint\n",
    "from langchain.chains import RetrievalQA\n",
    "\n",
    "llm = HuggingFaceEndpoint(\n",
    "    repo_id=\"google/flan-t5-base\",\n",
    "    temperature=0,\n",
    "    max_new_tokens=512,\n",
    ")\n",
    "\n",
    "qa_chain = RetrievalQA.from_chain_type(\n",
    "    llm=llm, chain_type=\"stuff\", retriever=retriever, return_source_documents=True\n",
    ")\n",
    "print(\"Pipeline: Ready\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d8f625c",
   "metadata": {},
   "source": [
    "## Test Cases"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50c3d033",
   "metadata": {},
   "source": [
    "### Question Helper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "529485b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Detect input and call qa_chain\n",
    "def ask(question: str):\n",
    "    want = list(getattr(qa_chain, \"input_keys\", []))  # e.g. ['query'] or ['input']\n",
    "    candidates = (want or []) + [\"query\", \"input\"]\n",
    "    last_err = None\n",
    "    for k in candidates:\n",
    "        try:\n",
    "            return qa_chain.invoke({k: question})\n",
    "        except Exception as e:\n",
    "            last_err = e\n",
    "            continue\n",
    "    raise RuntimeError(f\"Unable to invoke qa_chain. input_keys={want}\") from last_err\n",
    "\n",
    "\n",
    "def print_sources(result, preview=140, max_items=8):\n",
    "    print(\"\\nSources:\")\n",
    "    seen = set()\n",
    "    for i, d in enumerate(result.get(\"source_documents\", [])):\n",
    "        if i >= max_items: break\n",
    "        src = d.metadata.get(\"source\", \"unknown\")\n",
    "        if src in seen: \n",
    "            continue\n",
    "        seen.add(src)\n",
    "        page = d.metadata.get(\"page\", None)\n",
    "        page_str = f\" (p.{page+1})\" if isinstance(page, int) else \"\"\n",
    "        snippet = d.page_content.replace(\"\\n\", \" \").strip()\n",
    "        print(f\"- {src}{page_str} :: {snippet[:preview]}...\")\n",
    "        \n",
    "\n",
    "# Retrieve only\n",
    "def list_top_docs(query: str, k: int = 10, preview=120):\n",
    "    docs = retriever.get_relevant_documents(query)[:k]\n",
    "    print(f\"Top {len(docs)} matches for: {query}\\n\")\n",
    "    paths_seen = set()\n",
    "    rank = 1\n",
    "    for d in docs:\n",
    "        src = d.metadata.get(\"source\", \"unknown\")\n",
    "        if src in paths_seen: \n",
    "            continue\n",
    "        paths_seen.add(src)\n",
    "        page = d.metadata.get(\"page\", None)\n",
    "        page_str = f\" (p.{page+1})\" if isinstance(page, int) else \"\"\n",
    "        snippet = d.page_content.replace(\"\\n\", \" \").strip()\n",
    "        print(f\"{rank:>2}. {src}{page_str}\\n    {snippet[:preview]}...\\n\")\n",
    "        rank += 1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "705e03fe",
   "metadata": {},
   "source": [
    "### UC1: Find Particular Documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39568f37",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"UC1: Find Particular Documents\")\n",
    "q = \"Where is the CAPP final report from 2024?\"\n",
    "\n",
    "list_top_docs(q, k=10, preview=150)\n",
    "\n",
    "res = ask(q)\n",
    "print(\"\\nResponse:\\n\", res[\"result\"])\n",
    "print_sources(res)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb84198f",
   "metadata": {},
   "source": [
    "### UC2: Summarize Particular Documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d0925a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"UC2: Summarize Particular Documents\")\n",
    "q = \"Summarize the CAPP final report from 2024.\"\n",
    "\n",
    "res = ask(q)\n",
    "print(\"\\nSummary:\\n\", res[\"result\"])\n",
    "print_sources(res)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a9dd0c2",
   "metadata": {},
   "source": [
    "### UC3: Find Documents by Contents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a094f93d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"UC3: Find Documents by Contents\")\n",
    "q = \"Find documents related to system executive policies on AI.\"\n",
    "\n",
    "list_top_docs(q, k=12, preview=150)\n",
    "\n",
    "res = ask(q)\n",
    "print(\"\\nResponse:\\n\", res[\"result\"])\n",
    "print_sources(res)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df412962",
   "metadata": {},
   "source": [
    "### UC4: Finding Particular Information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09bf2cce",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"UC4: Finding Particular Information\")\n",
    "q = \"When were votes on AI policies conducted? Provide dates and where they appear.\"\n",
    "\n",
    "res = ask(q)\n",
    "\n",
    "print(\"\\nResponse:\\n\", res[\"result\"])\n",
    "print_sources(res)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c527360",
   "metadata": {},
   "source": [
    "### UC5: Finding Related Information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fb6e0ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"UC5: Finding Related Information (history)\")\n",
    "q = \"Show me the history of resolutions on GE. Include dates, brief summaries, and where they were recorded.\"\n",
    "\n",
    "res = ask(q)\n",
    "print(\"\\nResponse:\\n\", res[\"result\"])\n",
    "print_sources(res)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a986ea3",
   "metadata": {},
   "source": [
    "### UC6: Refinement of Found Information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7035c1fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"UC6: Refinement of Found Information\")\n",
    "q = \"In the history of GE resolutions you listed, which items support vs oppose GE reforms? Group them.\"\n",
    "\n",
    "res = ask(q)\n",
    "print(\"\\nResponse:\\n\", res[\"result\"])\n",
    "print_sources(res)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rag_workshop_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
